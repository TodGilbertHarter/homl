buildscript {
	repositories {
		maven {
			name 'localRepo'
			url uri('../localrepo')
		}
	}
	
	dependencies {
		classpath "com.google.javascript:closure-compiler:v20211201"
		classpath group: 'com.timgroup',
		name: 'gradle-webpack-plugin',
		version: '1.1.0'
		classpath 'com.sun.net.httpserver:http:20070405'
	}
	
}

plugins {
    id 'java'
    id 'io.quarkus'
	id "fr.brouillard.oss.gradle.jgitver" version "0.10.0-rc03"
	id "com.github.node-gradle.node" version "7.0.0"
//	id "com.timgroup.webpack" version "1.1.0"
}

apply plugin: com.timgroup.gradle.webpack.WebpackPlugin

configurations {
	saxon
}

group 'com.giantelectronicbrain'

repositories {
    mavenCentral()
    mavenLocal()
}

/** 
 * Note: this group of tasks were intended to allow importing of data from XWiki and as such are 
 * not really relevant anymore. They are retained here mostly for historical purposes and can
 * be ignored or deleted as needed.
 */
 
task copySaxon(type: Copy) {
	description 'get a copy of saxon binary into build dir'
	from configurations.saxon
	outputs.file("$buildDir/saxon")
	into "$buildDir/saxon"
}

task xsltErithnoiDM(type: Exec) {
	description 'run XSLT transforms on the DM content exported from xwiki to produce hairball code'
	dependsOn 'copySaxon'
	commandLine 'scripts/runSaxon.sh', 'src/main/xwiki/DungeonMaster', 'src/main/xwiki/article_to_hairball.xslt', 'build/etmp/DungeonMaster'
}

task xsltErithnoiPlayer(type: Exec) {
	description 'run XSLT transforms on the Player content exported from xwiki to produce hairball code'
	dependsOn 'copySaxon'
	commandLine 'scripts/runSaxon.sh', 'src/main/xwiki/Player', 'src/main/xwiki/article_to_hairball.xslt', 'build/etmp/Player'
}

task buildErithnoiDM(type: Exec) {
	description 'build the DM content directory to hold hairball version of xwiki content'
	dependsOn 'xsltErithnoiDM'
	commandLine 'scripts/buildErithnoi.sh', 'build/erithnoi/DungeonMaster', 'build/etmp/DungeonMaster'
}

task buildErithnoiPlayer(type: Exec) {
	description 'build the Player content directory to hold hairball version of xwiki content'
	dependsOn 'xsltErithnoiPlayer'
	commandLine 'scripts/buildErithnoi.sh', 'build/erithnoi/Player', 'build/etmp/Player'
}

task buildErithnoi {
	description 'build the content directory of all xwiki-derived hairball'
	dependsOn 'buildErithnoiPlayer'
	dependsOn 'buildErithnoiDM'	
}

/**
 * Clear the local build directory, but don't execute any other cleanups, note that
 * the standard 'clean' task will nuke node_modules, requiring a bunch of extra steps
 * in order to perform a build, so use this version instead if possible.
 */
task cleanLocal(type: Delete) {
	description 'clear out just the local build dir, saves time'
	delete buildDir
}

/**
 * NPM module install tasks. These need to be rerun after a 'clean'.
 */
 
task installClosureCompiler(type: NpmTask) {
	description 'npm install the google-closure-compiler module'
	args = ['install', 'google-closure-compiler']
}
	
task installFirebase(type: NpmTask) {
	description 'npm install the firebase and firebase-admin npm modules'
	args = ['install', 'firebase', 'firebase-admin', 'fakedb']
}

task installTestRunner(type: NpmTask) {
	description 'npm install the Playwright stuff so we can run in-browser tests'
	args = ['install', '--save-dev', '@web/test-runner', '@esm-bundle/chai']
//	args = ['install', '--save-dev', '@web/test-runner', '@web/test-runner-playwright', '@esm-bundle/chai']
}

task runAllJSTests(type: NpmTask) {
	args = ['run', 'test']
}

task generateErithnoi(type: Exec) {
	description 'compile all the xwiki-derived hairball to HTML'
	inputs.dir("src/main/erithnoi")
	inputs.file('scripts/generateErithnoi.sh')
	outputs.dir("$buildDir/erithnoipub")
	commandLine 'scripts/generateErithnoi.sh', project.version
}

dependencies {
	runtimeOnly "org.slf4j:slf4j-simple:1.7.30"
	compileOnly 'org.projectlombok:lombok:1.18.22'
	annotationProcessor 'org.projectlombok:lombok:1.18.22'
	testCompileOnly 'org.projectlombok:lombok:1.18.22'
	testAnnotationProcessor 'org.projectlombok:lombok:1.18.22'
    implementation enforcedPlatform("${quarkusPlatformGroupId}:${quarkusPlatformArtifactId}:${quarkusPlatformVersion}")
    implementation 'io.quarkus:quarkus-arc'
    implementation 'io.quarkus:quarkus-resteasy'
    implementation 'io.quarkus:quarkus-resteasy-jackson'
    implementation 'io.quarkus:quarkus-google-cloud-functions-http'
    implementation "io.quarkiverse.googlecloudservices:quarkus-google-cloud-firestore:${googleCloudServicesVersion}"
    testImplementation 'io.quarkus:quarkus-junit5'
    testImplementation 'io.rest-assured:rest-assured'
	saxon 'net.sf.saxon:Saxon-HE:10.6'
}

java {
    sourceCompatibility = JavaVersion.VERSION_17
    targetCompatibility = JavaVersion.VERSION_17
}

compileJava {
    options.encoding = 'UTF-8'
    options.compilerArgs << '-parameters'
}

test {
	environment "GOOGLE_APPLICATION_CREDENTIALS", "homl_firebase_credentials.json"
}

compileTestJava {
    options.encoding = 'UTF-8'
}

task disableGCPKey(type: Exec) {
//	commandLine './scripts/disableGCPKey.sh', "${project.getProperty('keyId')}"
}
	
task createGCPKey(type: Exec) {
//	commandLine "./scripts/createGCPKey.sh", "${project.getProperty('keyFile')}"
}

task deployFirebaseRules(type: Exec) {
	description 'deploy security rules to firebase'
	inputs.file('scripts/deployFirebaseRules.sh')
	inputs.dir('src/main/firebase')
	commandLine './scripts/deployFirebaseRules.sh'
}

task generateHoMLRules(type: Exec) {
	description 'generate the HOML rules from hairball source'
	inputs.dir('src/main/rules')
	inputs.file('scripts/generateHoMLRules.sh')
	outputs.dir("$buildDir/pub")
	commandLine './scripts/generateHoMLRules.sh', project.version
}

task deployHoMLRules(type: Exec) {
	description 'deploy generated HOML rules to cloud'
	dependsOn 'generateHoMLRules'
	inputs.dir("$buildDir/pub")
	commandLine './scripts/deployHoMLRules.sh', project.version
}

task copyGEBSite(type: Exec) {
	description 'copy source files for GEB to temp area in build directory'
	inputs.files(fileTree('src/main/site'))
	inputs.file('scripts/copyGEBSite.sh')
	outputs.dir('build/site')
	commandLine './scripts/copyGEBSite.sh', project.version
}

task generateEmptyCharacterSheet(type: Exec) {
	description 'generate an empty character sheet from the source'
	dependsOn 'copyGEBSite'
	inputs.file('scripts/generate_character.sh')
//	inputs.dir("$buildDir/site")
	commandLine './scripts/generate_character.sh', project.version, 'empty'
}

task generateGEBSite(type: Exec) {
	description 'build the GEB site, which is just the web application, from sources'
//	dependsOn 'generateHoMLRules'
	dependsOn 'generateEmptyCharacterSheet'
	inputs.file('scripts/generateGEBSite.sh')
	outputs.dir('build/geb')
	dependsOn 'copyGEBSite'
//	dependsOn 'closureCompile'
	commandLine './scripts/generateGEBSite.sh', project.version
}

task generateLocalSite(type: Exec) {
	description 'build a full local site with all features for testing, this can also be deployed remotely in one step'
	dependsOn 'generateHoMLRules'
	dependsOn 'generateErithnoi'
	dependsOn 'generateGEBSite'
	outputs.dir("$buildDir/local")
	inputs.file('scripts/generateLocalSite.sh')
	commandLine './scripts/generateLocalSite.sh', project.version
}

task deployAll(type: Exec) {
	description 'deploy the full site, including web application, rules, and erithnoi, to production'
	dependsOn 'generateLocalSite'
	inputs.dir("$buildDir/local");
	commandLine './scripts/deployAll.sh', project.version
}

/**
 * Plugin which implements a very basic web server using the old Sun httpserver package. This is well-supported
 * and will work in any version of Java. The server is pretty low-tech, but it works well. Start it via the supplied
 * startWebServer task, it will run in the background as long as the gradle daemon does.
 */
import com.sun.net.httpserver.*
import java.nio.file.Files
import java.nio.file.Paths
import java.nio.file.Path
import java.io.InputStream
import java.io.OutputStream
import java.io.FileInputStream

class HttpPlugin implements Plugin<Project>, HttpHandler {
	
	private void sendFile(String fileName, OutputStream os) {
		InputStream is = new FileInputStream(fileName);
		is.transferTo(os);
		os.flush();
		os.close();
	}
	
	private void setMIMEType(Headers h, String filename) {
		int extInd = filename.lastIndexOf(".");
		if(extInd != -1) {
			String mimeType = "";
			String extension = filename.substring(extInd);
			println("extension is "+extension);
			if(".html".equals(extension)) {
				mimeType = "text/html; charset=UTF-8";
			} else if(".js".equals(extension)) {
				mimeType = "application/javascript; charset=UTF-8";
			} else if(".css".equals(extension)) {
				mimeType = "text/css; charset=UTF-8";
			}
			if(!"".equals(mimeType))
				h.set("Content-Type", mimeType);
		}
	}
	
	public void handle(HttpExchange t) throws IOException {
		OutputStream os;
		boolean sentRH = false;
		try {
			println("handling request");
			String path = t.requestURI.decodedPath;
			println("got path of "+path);
			if("/".equals(path))
				path = "/index.html";
			println("path is now "+path);
			String filename = "/home/tharter/projects/homl/build/local"+path;
			println("filename is "+filename);
			println("CWD is "+System.getProperty('user.dir'));
			Path p = Path.of(filename);
			this.setMIMEType(t.responseHeaders,filename);
			println("got past getting the path");
			if(!Files.exists(p)) {
				t.sendResponseHeaders(404, -1);
				os = t.getResponseBody();
				os.close();
				return;
			}
			long size = Files.size(p);
			println("Size is "+size);
			t.sendResponseHeaders(200, size);
			sentRH = true;
			println("sent response headers "+size);
			os = t.getResponseBody();
			this.sendFile(filename, os);
			println("done");
		} catch(Throwable e) {
			e.printStackTrace();
			if(!sentRH) t.sendResponseHeaders(500, -1);
			if(os != null) os.close();
		}
	}
	
	void apply(Project project) {
		project.task('startWebServer') {
			doLast {
				HttpServer server = HttpServer.create(new InetSocketAddress(8080), 0);
				server.createContext("/", this);
				server.setExecutor(null);
				server.start();
			}
		}
	}
}

apply plugin: HttpPlugin

task uploadBoons(type: NodeTask) {
	description 'upload boon data to firestore.'
	script = file('./scripts/upload_boons.js')
	args = ['build/rules/compendium.json']
}

task uploadFeats(type: NodeTask) {
	description 'upload feat data to firestore'
	script = file('./scripts/upload_feats.js')
	args = ['build/rules/compendium.json']
}

task uploadCallings(type: NodeTask) {
	description 'upload calling data to firestore'
	script = file('./scripts/upload_callings.js')
	args = ['build/rules/compendium.json']
}

task uploadSpecies(type: NodeTask) {
	description 'upload species data to firestore'
	script = file('./scripts/upload_species.js')
	args = ['build/rules/compendium.json']
}

task uploadOrigins(type: NodeTask) {
	description 'upload heroic origin data to firestore'
	script = file('./scripts/upload_origins.js')
	args = ['build/rules/compendium.json']
}

task uploadBackgrounds(type: NodeTask) {
	description 'upload background data to firestore'
	script = file('./scripts/upload_backgrounds.js')
	args = ['build/rules/compendium.json']
}

task uploadData {
	description 'upload compendium data to firestore'
	dependsOn 'uploadBoons'
	dependsOn 'uploadFeats'
	dependsOn 'uploadCallings'
	dependsOn 'uploadSpecies'
	dependsOn 'uploadOrigins'
	dependsOn 'uploadBackgrounds'
}

task closureCompile(type: NpxTask) {
	description 'use closure-compiler to build a production version of GEB js library, this will fail until we understand module imports'
	dependsOn 'npm_install'
	dependsOn 'copyGEBSite'
	command = 'google-closure-compiler'
	args = ['--language_in', 'ES_NEXT', 
		'--js_module_root', 'node_modules',
		'-O', 'SIMPLE', 
		'--js', 'build/site/js/*.js', 
		'--js_output_file', "build/geb/geb-${project.version}/js/library.js"]
//	args = ['--version']
}
	
/* task getCCJar(type: Copy) {
	from buildscript.configurations.classpath
	into "${project.buildDir}/cc"
}

task closureCompile(type: Exec) {
	dependsOn 'getCCJar'
	dependsOn 'copyGEBSite'
	commandLine './scripts/runClosureCompiler.sh', project.version
} */
